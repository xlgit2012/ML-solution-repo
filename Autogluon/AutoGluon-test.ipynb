{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"./images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n",
    "\n",
    "# MLU Day One Machine Learning - Hands On\n",
    "\n",
    "This hands-on notebook will let you practice the concepts you have learned in this course so far.\n",
    "In the notebook, you will explore a database of books (books of different genres, from thousands of authors).\n",
    "The goal is to predict book prices using book features.\n",
    "\n",
    "__Business Problem:__ Books from a large database of books - different genres, thousands of authors, etc., cannot be listed for sale because they are missing one critical piece of information, the price. \n",
    "\n",
    "__ML Problem Description:__ Predict book prices using book features, such as genre, release data, ratings, number of reviews.  \n",
    "> This is a __regression__ task (we have a book price column in our train dataset that we can use as labels). <br>\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "To generate book price predictions, you will be presented with two kinds of exercises throughout the notebook: __TASKS__ and __CHALLENGES__. <br/>\n",
    "\n",
    "\n",
    "| <img style=\"float: center;\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/>| <img style=\"float: center;\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/>|\n",
    "|:---    |   ---  |\n",
    "| No coding needed for theses tasks. <br /> Try to understand what is happening and run the cells & code associated to this. | These are challenges where you can practice your coding skills. <br /> Once done, uncomment the challenge asnwer and check your solution.\n",
    "| || \n",
    "\n",
    "As we are not trying to measure your coding skills, you will find solutions throughout the notebook: \n",
    "All the challenges have answers that you can copy and paste into the challlenge coding area: **No matter how experienced and skilled you are with coding, you will be able to submit a solution!**\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "The notebook consits of 2 parts; please work top to bottom and don't skip sections as this could lead to error messages due to missing code.\n",
    "\n",
    "### <a href=\"#1\">Part I - Leaderboard Submission</a>\n",
    "In the first part of the notebook you are going to learn how [__AutoGluon__](https://auto.gluon.ai/stable/index.html#) can solve the book price prediction problem.<br/>\n",
    "\n",
    "You will learn how to build a simple and quick base model and then implement iterations of this model to improve it. To measure how well you are doing (and to see how the model improves) you have to submit your model's predictions to the [__Book Prices Prediction MLU Leaderboard__](https://mlu.corp.amazon.com/contests/redirect/7). Leaderboard will assess your prediction performance against other participants. Your submission to the leaderboard also __counts towards your course completion__. \n",
    "\n",
    "We ask you to make 2 submissions in Part I:<br/>\n",
    "1. First a simple prediction trained with a smaller dataset (for a quick first submisison).\n",
    "2. Then another prediction trained with a full dataset, in order to submit an improved result.\n",
    "\n",
    "Feel free to keep improving your model and make as many submissions as you like to Leaderboard. \n",
    "\n",
    "### <a href=\"#2\">Part II - Advanced AutoGluon (OPTIONAL)</a>\n",
    "In the second part of the notebook you will find some advanced features of AutoGluon. You're welcome to use the insights you can gain from Part II to make an optional 3rd submission. However, a quick word of warning - AutoGluon is very powerful in its base form so you might not see much additional model improvement on Leaderboard.\n",
    "\n",
    "----\n",
    "</br>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"1\">Part I - Leaderboard Submission</a>\n",
    "Let's solve the book price prediction problem using __AutoGluon__.\n",
    "\n",
    "- Part I - 1. <a href=\"#p1-1\">AutoGluon Installation</a>\n",
    "- Part I - 2. <a href=\"#p1-2\">Getting the Data</a>\n",
    "- Part I - 3. <a href=\"#p1-3\">Model Training with AutoGluon (small train dataset)</a>\n",
    "- Part I - 4. <a href=\"#p1-4\">AutoGluon Training Results</a>\n",
    "- Part I - 5. <a href=\"#p1-5\">Model Prediction with AutoGluon</a>\n",
    "- Part I - 6. <a href=\"#p1-6\">First MLU Leaderboard Submission (with small train data)</a>\n",
    "- Part I - 7. <a href=\"#p1-7\">Second MLU Leaderboard Submission (with full train data)</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Please make sure to run the below cell! It will allow you to print solutions for the code challenges.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utility functions that provide answers to challenges\n",
    "%load_ext autoreload\n",
    "%aimport dayone_utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"p1-1\">Part I - 1. AutoGluon Installation</a>\n",
    "\n",
    "We need to begin by installing AutoGluon (documentation [here](https://auto.gluon.ai/stable/install.html)).  \n",
    "\n",
    "\n",
    "__NOTE__: This may take a few minutes to install (you can see that it has finished once the `[*]` symbol next to the cell disappears and turns into a number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install -qU pip\n",
    "#!python3 -m pip install -qU setuptools wheel\n",
    "#!python3 -m pip install -qU \"mxnet<2.0.0\"\n",
    "#!python3 -m pip install -qU autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the libraries needed to work with our Tabular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the newly installed AutoGluon code library\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a name=\"p1-2\">Part I - 2. Getting the Data</a>\n",
    "\n",
    "Let's get the data for our business problem.\n",
    "\n",
    ">  <img style=\"float: left; padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\" /> \n",
    ">  Run the cell below to load the train and test data. Then continue and take a look at the first samples of our train dataset. <br/> This is a very basic check when performing __Data Exploration__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ./datasets/training.csv | Columns = 10 / 10 | Rows = 5051 -> 5051\n",
      "Loaded data from: ./datasets/mlu-leaderboard-test.csv | Columns = 9 / 9 | Rows = 562 -> 562\n"
     ]
    }
   ],
   "source": [
    "df_train = TabularDataset(data=\"./datasets/training.csv\")\n",
    "df_test = TabularDataset(data=\"./datasets/mlu-leaderboard-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Genre</th>\n",
       "      <th>BookCategory</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>542</td>\n",
       "      <td>Foe (Penguin Essentials)</td>\n",
       "      <td>J. M. Coetzee</td>\n",
       "      <td>Paperback,– 21 Sep 2010</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>2 customer reviews</td>\n",
       "      <td>Nobel Laureate and two-time Booker prize-winni...</td>\n",
       "      <td>Action &amp; Adventure (Books)</td>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>2.527630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2380</td>\n",
       "      <td>Of Blood and Bone (Chronicles of The One)</td>\n",
       "      <td>Nora Roberts</td>\n",
       "      <td>Paperback,– 25 Jan 2019</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>5 customer reviews</td>\n",
       "      <td>Thirteen years ago, a catastrophic pandemic kn...</td>\n",
       "      <td>Action &amp; Adventure (Books)</td>\n",
       "      <td>Romance</td>\n",
       "      <td>2.555094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5529</td>\n",
       "      <td>Then She Was Gone</td>\n",
       "      <td>Lisa Jewell</td>\n",
       "      <td>Paperback,– Import, 14 Dec 2017</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>9 customer reviews</td>\n",
       "      <td>BESTSELLING PSYCHOLOGICAL SUSPENSE, AND A TOP ...</td>\n",
       "      <td>Action &amp; Adventure (Books)</td>\n",
       "      <td>Crime, Thriller &amp; Mystery</td>\n",
       "      <td>2.531479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4511</td>\n",
       "      <td>Mongodb: The Definitive Guide- Powerful and Sc...</td>\n",
       "      <td>Kristina Chodorow</td>\n",
       "      <td>Paperback,– 2013</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>11 customer reviews</td>\n",
       "      <td>Manage the huMONGOus amount of data collected ...</td>\n",
       "      <td>Computer Databases (Books)</td>\n",
       "      <td>Computing, Internet &amp; Digital Media</td>\n",
       "      <td>2.845718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305</td>\n",
       "      <td>Jerusalem: The Biography</td>\n",
       "      <td>Simon Sebag Montefiore</td>\n",
       "      <td>Paperback,– 1 Mar 2012</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>18 customer reviews</td>\n",
       "      <td>The epic story of Jerusalem told through the l...</td>\n",
       "      <td>History of Civilization &amp; Culture</td>\n",
       "      <td>Biographies, Diaries &amp; True Accounts</td>\n",
       "      <td>2.733197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                              Title  \\\n",
       "0   542                           Foe (Penguin Essentials)   \n",
       "1  2380          Of Blood and Bone (Chronicles of The One)   \n",
       "2  5529                                  Then She Was Gone   \n",
       "3  4511  Mongodb: The Definitive Guide- Powerful and Sc...   \n",
       "4  1305                           Jerusalem: The Biography   \n",
       "\n",
       "                   Author                          Edition  \\\n",
       "0           J. M. Coetzee          Paperback,– 21 Sep 2010   \n",
       "1            Nora Roberts          Paperback,– 25 Jan 2019   \n",
       "2             Lisa Jewell  Paperback,– Import, 14 Dec 2017   \n",
       "3       Kristina Chodorow                 Paperback,– 2013   \n",
       "4  Simon Sebag Montefiore           Paperback,– 1 Mar 2012   \n",
       "\n",
       "              Reviews              Ratings  \\\n",
       "0  5.0 out of 5 stars   2 customer reviews   \n",
       "1  4.3 out of 5 stars   5 customer reviews   \n",
       "2  4.0 out of 5 stars   9 customer reviews   \n",
       "3  4.7 out of 5 stars  11 customer reviews   \n",
       "4  4.6 out of 5 stars  18 customer reviews   \n",
       "\n",
       "                                            Synopsis  \\\n",
       "0  Nobel Laureate and two-time Booker prize-winni...   \n",
       "1  Thirteen years ago, a catastrophic pandemic kn...   \n",
       "2  BESTSELLING PSYCHOLOGICAL SUSPENSE, AND A TOP ...   \n",
       "3  Manage the huMONGOus amount of data collected ...   \n",
       "4  The epic story of Jerusalem told through the l...   \n",
       "\n",
       "                               Genre                          BookCategory  \\\n",
       "0         Action & Adventure (Books)                    Action & Adventure   \n",
       "1         Action & Adventure (Books)                               Romance   \n",
       "2         Action & Adventure (Books)             Crime, Thriller & Mystery   \n",
       "3         Computer Databases (Books)   Computing, Internet & Digital Media   \n",
       "4  History of Civilization & Culture  Biographies, Diaries & True Accounts   \n",
       "\n",
       "      Price  \n",
       "0  2.527630  \n",
       "1  2.555094  \n",
       "2  2.531479  \n",
       "3  2.845718  \n",
       "4  2.733197  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"p1-3\">Part I - 3. Model Training with AutoGluon (small train dataset)</a>\n",
    "\n",
    "We can train a model using AutoGluon with only a single line of code.  All we need to do is to tell it which column from the dataset we are trying to predict, and what the dataset is.\n",
    "\n",
    "\n",
    "### Sampling data\n",
    "For this first training, we are going to randomly sample 1000 samples of our train dataset in order to have a faster training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/>  Run the cell below to prepare the datasets (AutoGluon is doing all the magic for us). <br/>\n",
    "Here we are randomly selecting 1000 rows of our dataset and splitting it into train and validation datasets.\n",
    "> \n",
    "\n",
    "<br/>\n",
    "\n",
    "__NOTE__: The `random_state` parameter below alows to have repeatability when running the code multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Genre</th>\n",
       "      <th>BookCategory</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>3990</td>\n",
       "      <td>Beast</td>\n",
       "      <td>Krishna Udayasankar</td>\n",
       "      <td>Paperback,– 25 Mar 2019</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>34 customer reviews</td>\n",
       "      <td>An urban adventure thriller inspired by the legend of the Narasimha Avatar and explained through Genetics.\\n\\nIt was always the same dream, a dream that began with darkness and blood.\\nWhen Assistant Commissioner of Police Aditi Kashyap is called upon to solve a gruesome triple homicide in a Mumbai suburb, she is dragged into the terrifying world of the Saimhas -- werelions -- who have lived alongside humans, hiding amongst them, since ancient times.\\nFaced with the unbelievable, Aditi has no choice but to join hands with Prithvi, an Enforcer called in to hunt down this seemingly otherworl...</td>\n",
       "      <td>Crime, Thriller &amp; Mystery (Books)</td>\n",
       "      <td>Crime, Thriller &amp; Mystery</td>\n",
       "      <td>2.378398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>4327</td>\n",
       "      <td>Theory of Computation</td>\n",
       "      <td>Vivek Kulkarni</td>\n",
       "      <td>Paperback,– 12 Apr 2013</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>1 customer review</td>\n",
       "      <td>The book begins with basic concepts such as symbols, alphabets, sets, relations, graphs, strings, and languages. It then delves into the important topics including separate chapters on finite state machine, regular expressions, grammars, pushdown stack, Turing machine, parsing techniques, Post machine, undecidability, and complexity of problems. A chapter on production systems encompasses a computational model which is different from the Turing model, called Markov and labelled Markov algorithms. At the end, the chapter on implementations provides implementation of some key concepts especi...</td>\n",
       "      <td>Computer Science Books</td>\n",
       "      <td>Computing, Internet &amp; Digital Media</td>\n",
       "      <td>2.542825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>2352</td>\n",
       "      <td>Tom Gates #11: Dog Zombies Rule</td>\n",
       "      <td>Liz Pichon</td>\n",
       "      <td>Hardcover,– 10 Feb 2017</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>15 customer reviews</td>\n",
       "      <td>Here's my excellent plan to make DogZombies the best band in the whole wide world! How hard can it be? (Very.) Right now I'm going to: 1. Write more songs. (Not about teachers.) 2. Make a spectacular music video. (Easy.) 3. Get some sleep. (Tricky when you're being kept awake by loud noises.) 4. Annoy Delia. (Nothing to do with dogzombies but always FUN.)\\n\\nWinner of\\nThe Roald Dahl Funny Prize\\nThe Red House Book Award Best Book for Young Readers\\nThe Waterstone's Best Fiction for 5-12 year old's\\nThe Blue Peter Award for Best Story.</td>\n",
       "      <td>Comics</td>\n",
       "      <td>Comics &amp; Mangas</td>\n",
       "      <td>2.376577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2255</td>\n",
       "      <td>Only Time Will Tell (The Clifton Chronicles)</td>\n",
       "      <td>Jeffrey Archer</td>\n",
       "      <td>Paperback,– 15 Sep 2011</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>298 customer reviews</td>\n",
       "      <td>The Clifton Chronicles is Jeffrey Archer’s most ambitious work in four decades as an international bestselling author. The epic tale of Harry Clifton’s life begins in 1919, in the backstreets of Bristol. His father was a war hero, but it will be twenty-one tumultuous years before Harry discovers the truth about how his father really died and if, in fact, he even was his father. The first in the series, Only Time Will Tell takes a cast of memorable characters from the ravages of the Great War to the outbreak of the Second World War, when Harry must decide whether to take his place at Oxford...</td>\n",
       "      <td>Action &amp; Adventure (Books)</td>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>2.071882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>2596</td>\n",
       "      <td>Arnold's Bodybuilding for Men</td>\n",
       "      <td>Schwarzenegger</td>\n",
       "      <td>Paperback,– 12 Oct 1984</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>13 customer reviews</td>\n",
       "      <td>The complete program for building and maintaining a well-conditioned, excellently proportioned body—for a lifetime of fitness and health.\\n\\nIn Arnold's Bodybuilding for Men, legendary athlete Arnold Schwarzenegger shows you how to achieve the best physical condition of your life. For every man, at every age, Arnold outlines a step-by-step program of excercise, skillfully combining weight training and aerobic conditioning. The result—total cardiovascular and muscular fitness.\\n\\nArnold's program of exercise features stretching, warm-up and warm-down routines, and three series of exercises,...</td>\n",
       "      <td>Healthy Living &amp; Wellness (Books)</td>\n",
       "      <td>Sports</td>\n",
       "      <td>2.764176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                         Title               Author  \\\n",
       "4097  3990                                         Beast  Krishna Udayasankar   \n",
       "1622  4327                         Theory of Computation       Vivek Kulkarni   \n",
       "1861  2352               Tom Gates #11: Dog Zombies Rule           Liz Pichon   \n",
       "39    2255  Only Time Will Tell (The Clifton Chronicles)       Jeffrey Archer   \n",
       "2839  2596                 Arnold's Bodybuilding for Men       Schwarzenegger   \n",
       "\n",
       "                      Edition             Reviews               Ratings  \\\n",
       "4097  Paperback,– 25 Mar 2019  4.6 out of 5 stars   34 customer reviews   \n",
       "1622  Paperback,– 12 Apr 2013  1.0 out of 5 stars     1 customer review   \n",
       "1861  Hardcover,– 10 Feb 2017  4.7 out of 5 stars   15 customer reviews   \n",
       "39    Paperback,– 15 Sep 2011  4.2 out of 5 stars  298 customer reviews   \n",
       "2839  Paperback,– 12 Oct 1984  4.2 out of 5 stars   13 customer reviews   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Synopsis  \\\n",
       "4097  An urban adventure thriller inspired by the legend of the Narasimha Avatar and explained through Genetics.\\n\\nIt was always the same dream, a dream that began with darkness and blood.\\nWhen Assistant Commissioner of Police Aditi Kashyap is called upon to solve a gruesome triple homicide in a Mumbai suburb, she is dragged into the terrifying world of the Saimhas -- werelions -- who have lived alongside humans, hiding amongst them, since ancient times.\\nFaced with the unbelievable, Aditi has no choice but to join hands with Prithvi, an Enforcer called in to hunt down this seemingly otherworl...   \n",
       "1622  The book begins with basic concepts such as symbols, alphabets, sets, relations, graphs, strings, and languages. It then delves into the important topics including separate chapters on finite state machine, regular expressions, grammars, pushdown stack, Turing machine, parsing techniques, Post machine, undecidability, and complexity of problems. A chapter on production systems encompasses a computational model which is different from the Turing model, called Markov and labelled Markov algorithms. At the end, the chapter on implementations provides implementation of some key concepts especi...   \n",
       "1861                                                            Here's my excellent plan to make DogZombies the best band in the whole wide world! How hard can it be? (Very.) Right now I'm going to: 1. Write more songs. (Not about teachers.) 2. Make a spectacular music video. (Easy.) 3. Get some sleep. (Tricky when you're being kept awake by loud noises.) 4. Annoy Delia. (Nothing to do with dogzombies but always FUN.)\\n\\nWinner of\\nThe Roald Dahl Funny Prize\\nThe Red House Book Award Best Book for Young Readers\\nThe Waterstone's Best Fiction for 5-12 year old's\\nThe Blue Peter Award for Best Story.   \n",
       "39    The Clifton Chronicles is Jeffrey Archer’s most ambitious work in four decades as an international bestselling author. The epic tale of Harry Clifton’s life begins in 1919, in the backstreets of Bristol. His father was a war hero, but it will be twenty-one tumultuous years before Harry discovers the truth about how his father really died and if, in fact, he even was his father. The first in the series, Only Time Will Tell takes a cast of memorable characters from the ravages of the Great War to the outbreak of the Second World War, when Harry must decide whether to take his place at Oxford...   \n",
       "2839  The complete program for building and maintaining a well-conditioned, excellently proportioned body—for a lifetime of fitness and health.\\n\\nIn Arnold's Bodybuilding for Men, legendary athlete Arnold Schwarzenegger shows you how to achieve the best physical condition of your life. For every man, at every age, Arnold outlines a step-by-step program of excercise, skillfully combining weight training and aerobic conditioning. The result—total cardiovascular and muscular fitness.\\n\\nArnold's program of exercise features stretching, warm-up and warm-down routines, and three series of exercises,...   \n",
       "\n",
       "                                  Genre                         BookCategory  \\\n",
       "4097  Crime, Thriller & Mystery (Books)            Crime, Thriller & Mystery   \n",
       "1622             Computer Science Books  Computing, Internet & Digital Media   \n",
       "1861                             Comics                      Comics & Mangas   \n",
       "39           Action & Adventure (Books)                   Action & Adventure   \n",
       "2839  Healthy Living & Wellness (Books)                               Sports   \n",
       "\n",
       "         Price  \n",
       "4097  2.378398  \n",
       "1622  2.542825  \n",
       "1861  2.376577  \n",
       "39    2.071882  \n",
       "2839  2.764176  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell\n",
    "\n",
    "# Sampling 1000\n",
    "subsample_size = 1000  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "df_train_smaller = df_train.sample(n=subsample_size, random_state=0)\n",
    "\n",
    "# Printing the first rows\n",
    "df_train_smaller.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model with our small sample\n",
    "\n",
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/> \n",
    "For this first training we are going to use the smaller dataset with 1000 samples of our original train dataset in order to have a faster training.\n",
    "\n",
    "__NOTE__: AutoGluon uses certain defaults; generally these are good but there is one exception: `eval_metric`.  By default, AutoGluon uses `‘root_mean_squared_error’` as evaluation metric for regression problems. However, MLU Leaderboard is using the `‘mean_squared_error’` metric to measure submissions quality, so we need to explictly pass this metric to AutoGluon. For more information on these options, see sklearn [metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics).\n",
    "\n",
    "\n",
    "---\n",
    "Let's use `TabularPredictor` to train the first version of our model.\n",
    "\n",
    "__NOTE__: Training on this smaller dataset might still take approx. 3-4 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220209_231254\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220209_231254\\\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 9\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (3.9542425094393248, 1.414973347970818, 2.60143, 0.33874)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    929.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.05 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Title', 'Edition', 'Reviews', 'Ratings', 'Synopsis', 'Genre']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 875\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 875 to 526 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['ID']\n",
      "\t\t('object', [])       : 2 | ['Author', 'BookCategory']\n",
      "\t\t('object', ['text']) : 6 | ['Title', 'Edition', 'Reviews', 'Ratings', 'Synopsis', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   2 | ['Author', 'BookCategory']\n",
      "\t\t('category', ['text_as_category'])  :   6 | ['Title', 'Edition', 'Reviews', 'Ratings', 'Synopsis', ...]\n",
      "\t\t('int', [])                         :   1 | ['ID']\n",
      "\t\t('int', ['binned', 'text_special']) :  63 | ['Title.char_count', 'Title.word_count', 'Title.capital_ratio', 'Title.lower_ratio', 'Title.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 526 | ['__nlp__.10', '__nlp__.11', '__nlp__.12', '__nlp__.13', '__nlp__.14', ...]\n",
      "\t5.0s = Fit runtime\n",
      "\t9 features in original data used to generate 598 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.14 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.1382\t = Validation score   (mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.1463\t = Validation score   (mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-0.065\t = Validation score   (mean_squared_error)\n",
      "\t1.68s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-0.0648\t = Validation score   (mean_squared_error)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.0669\t = Validation score   (mean_squared_error)\n",
      "\t3.8s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.0619\t = Validation score   (mean_squared_error)\n",
      "\t15.36s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.0693\t = Validation score   (mean_squared_error)\n",
      "\t3.94s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 4: early stopping\n",
      "\t-0.0721\t = Validation score   (mean_squared_error)\n",
      "\t7.38s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.0676\t = Validation score   (mean_squared_error)\n",
      "\t1.94s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-0.07\t = Validation score   (mean_squared_error)\n",
      "\t8.42s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.0602\t = Validation score   (mean_squared_error)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 51.57s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220209_231254\\\")\n"
     ]
    }
   ],
   "source": [
    "# Run this cell\n",
    "\n",
    "smaller_predictor = TabularPredictor(label=\"Price\", eval_metric=\"mean_squared_error\").fit(train_data=df_train_smaller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Training Output\n",
    "AutoGluon outputs a lot of information about what is happening.\n",
    "\n",
    "<img style=\"float: left;\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/> \n",
    "<br/><br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "> After the prediction above finishes, examine the output and try to find the information below in the print out messages from AutoGluon. <br/>\n",
    "1. What is the shape of your training dataset?\n",
    "2. What kind of ML problem type does AutoGluon infer (classification, regression, ...)? Remember, you've never mentioned what kind of problem type it is; you only provided the label column.\n",
    "3. What does AutoGluon suggest in case it inferred the wrong problem type?\n",
    "4. Identify the kind of data preprocessing and feature engineering performed by AutoGluon.\n",
    "5. Find the basic statistics about your label in the print statements from AutoGluon.\n",
    "6. How many extra features were generated besides the originals in our dataset? What was the runtime for that?\n",
    "7. What is the evaluation metric used?\n",
    "8. What does AutoGluon suggests to do if it inferred the wrong metric?\n",
    "9. What is the ration between train & validation dataset (try looking for `val` or `validation`)?\n",
    "10. Identify the folder where the models are saved.\n",
    "11. Identify where AutoGluon saved your prediction.\n",
    "12. Enter a specific model folder and take a quick look to see the file format.\n",
    "\n",
    "__Please, try hard to identify all information above before uncommenting the answer below.__ <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################# LIST YOUR ANSWERS HERE #################\n",
    "1. Train Data Rows: 1000, Train Data Columns: 9 <br/>\n",
    "2. Regression <br/>\n",
    "3. manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'] <br/>\n",
    "4. (1) AsType, (2) FillNa, (3) Identity, Category(CategoryMemoryMinimize), TextSpecial(Binned, DropDuplicates), TextNgram(CountVectorizer - reducing Vectorizer vocab size from 875 to 526), (4) DropUnique ==>  9 features in original data used to generate 598 features in processed data <br/>\n",
    "5. Label info (max, min, mean, stddev): (3.9542425094393248, 1.414973347970818, 2.60143, 0.33874) <br/>\n",
    "6. 9 features in original data used to generate 598 features in processed data, 5.11s <br/>\n",
    "7. mean_squared_error <br/>\n",
    "8. specify the eval_metric argument of fit() <br/>\n",
    "9. 0.8 vs 0.2, Train Rows: 800, Val Rows: 200 <br/>\n",
    "10. AutogluonModels/ag-20220209_231254 <br/>\n",
    "11. AutogluonModels/ag-20220209_231254 <br/>\n",
    "12. model.pkl <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CHALLENGE ANSWER\n",
    "# dayone_utils.answer_html(\"CH_FIT_INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"p1-4\">Part I - 4. AutoGluon Results</a>\n",
    "Now let's take a look at all the information AutoGluon provides via its __leaderboard function__. <br/> \n",
    "\n",
    "__NOTE__: Don't confuse this with the MLU Leaderboard. The MLU Leaderboard is where you will make submissions with the predictions from your trained models; the AutoGluon leaderboard function is a summary of all models that AutoGluon trained.\n",
    "\n",
    "<br/>\n",
    "\n",
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/> \n",
    "> Run the cell below and take a closer look at AutoGluon's leaderboard output. <br/>\n",
    "__Which one is the best model?__\n",
    "\n",
    "<br/>\n",
    "\n",
    "__NOTE__: As AutoGluon only maximizes metrics, you will see a negative MSE value, for prioritization purposes only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.060205</td>\n",
       "      <td>0.423705</td>\n",
       "      <td>27.805055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269403</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.061911</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>15.360326</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>15.360326</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.064838</td>\n",
       "      <td>0.036998</td>\n",
       "      <td>1.181352</td>\n",
       "      <td>0.036998</td>\n",
       "      <td>1.181352</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.064974</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.676940</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.676940</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-0.066901</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>3.798078</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>3.798078</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.067591</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>1.935345</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>1.935345</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-0.069272</td>\n",
       "      <td>0.071544</td>\n",
       "      <td>3.943585</td>\n",
       "      <td>0.071544</td>\n",
       "      <td>3.943585</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-0.070022</td>\n",
       "      <td>0.056001</td>\n",
       "      <td>8.418169</td>\n",
       "      <td>0.056001</td>\n",
       "      <td>8.418169</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-0.072054</td>\n",
       "      <td>0.284660</td>\n",
       "      <td>7.381691</td>\n",
       "      <td>0.284660</td>\n",
       "      <td>7.381691</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-0.138151</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.146264</td>\n",
       "      <td>0.016815</td>\n",
       "      <td>0.022997</td>\n",
       "      <td>0.016815</td>\n",
       "      <td>0.022997</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val   fit_time  \\\n",
       "0   WeightedEnsemble_L2  -0.060205       0.423705  27.805055   \n",
       "1              CatBoost  -0.061911       0.042046  15.360326   \n",
       "2              LightGBM  -0.064838       0.036998   1.181352   \n",
       "3            LightGBMXT  -0.064974       0.040000   1.676940   \n",
       "4       RandomForestMSE  -0.066901       0.053004   3.798078   \n",
       "5               XGBoost  -0.067591       0.020001   1.935345   \n",
       "6         ExtraTreesMSE  -0.069272       0.071544   3.943585   \n",
       "7         LightGBMLarge  -0.070022       0.056001   8.418169   \n",
       "8       NeuralNetFastAI  -0.072054       0.284660   7.381691   \n",
       "9        KNeighborsUnif  -0.138151       0.021029   0.035250   \n",
       "10       KNeighborsDist  -0.146264       0.016815   0.022997   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000000           0.269403            2       True   \n",
       "1                 0.042046          15.360326            1       True   \n",
       "2                 0.036998           1.181352            1       True   \n",
       "3                 0.040000           1.676940            1       True   \n",
       "4                 0.053004           3.798078            1       True   \n",
       "5                 0.020001           1.935345            1       True   \n",
       "6                 0.071544           3.943585            1       True   \n",
       "7                 0.056001           8.418169            1       True   \n",
       "8                 0.284660           7.381691            1       True   \n",
       "9                 0.021029           0.035250            1       True   \n",
       "10                0.016815           0.022997            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          11  \n",
       "1           6  \n",
       "2           4  \n",
       "3           3  \n",
       "4           5  \n",
       "5           9  \n",
       "6           7  \n",
       "7          10  \n",
       "8           8  \n",
       "9           1  \n",
       "10          2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell\n",
    "\n",
    "smaller_predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CHALLENGE ANSWER\n",
    "# dayone_utils.answer_html(\"CH_BEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"p1-5\">Part I - 5. Model Prediction with AutoGluon</a>\n",
    "#### Now that your model is trained, let's use it to predict prices!\n",
    "\n",
    "We should always run a final model performance assessment using data that was unseen by the model (the test data). Test data is not used during training and can therefore give a performance assesment. In our case, we will use the test data to make predictions and submit those to MLU Leaderboard in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/> \n",
    "Run the cell below to show the test dataset that we will use for the MLU Leaderboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Genre</th>\n",
       "      <th>BookCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1589</td>\n",
       "      <td>R in Action, 2ed (MANNING)</td>\n",
       "      <td>Robert L. Kabacoff</td>\n",
       "      <td>Paperback,– 2015</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>7 customer reviews</td>\n",
       "      <td>R in Action, Second Edition teaches you how to use the R language by presenting examples relevant to scientific, technical and business developers. Focusing on practical solutions, the book offers a crash course in statistics, including elegant methods for dealing with messy and incomplete data. You'll also master R's extensive graphical capabilities for exploring and presenting data visually. And this expanded second edition includes new chapters on forecasting, data mining and dynamic report writing.</td>\n",
       "      <td>Computer Science Books</td>\n",
       "      <td>Computing, Internet &amp; Digital Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2125</td>\n",
       "      <td>The Duchess Deal: Girl Meets Duke</td>\n",
       "      <td>Tessa Dare</td>\n",
       "      <td>Mass Market Paperback,– 22 Aug 2017</td>\n",
       "      <td>4.8 out of 5 stars</td>\n",
       "      <td>7 customer reviews</td>\n",
       "      <td>An iBooks Best Romance of August Pick!\\nOne of Publishers Weekly's Buzz Books of Romance 2017!\\nAn Amazon Best Romance of August Pick!\\n2017 RT Reviewer's Choice Book of the Year Nominee and 2017 RT Reviewer's Choice Nominee for Best Historical Love &amp; Laughter!\\n When girl meets Duke, their marriage breaks all the rules…\\nSince his return from war, the Duke of Ashbury’s to-do list has been short and anything but sweet: brooding, glowering, menacing London ne’er-do-wells by night. Now there’s a new item on the list. He needs an heir—which means he needs a wife. When Emma Gladstone, a vicar’...</td>\n",
       "      <td>Romance (Books)</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5516</td>\n",
       "      <td>Learning React: Functional Web Development with React and Redux</td>\n",
       "      <td>Alex Banks</td>\n",
       "      <td>Paperback,– 2017</td>\n",
       "      <td>4.8 out of 5 stars</td>\n",
       "      <td>6 customer reviews</td>\n",
       "      <td>\"If you want to learn how to build efficient user interfaces with React, this is your book. Authors Alex Banks and Eve Porcello show you how to create UIs with this small JavaScript library that can deftly display data changes on large-scale, data-driven websites without page reloads. Along the way, youíll learn how to work with functional programming and the latest ECMAScript features.\\nDeveloped by Facebook and used by companies including Netflix, Walmart and The New York Times for large parts of their web interfaces, React is quickly growing in use. By learning how to build React compon...</td>\n",
       "      <td>Internet &amp; Web (Books)</td>\n",
       "      <td>Computing, Internet &amp; Digital Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1307</td>\n",
       "      <td>Sikkim - Dawn of Democracy: The Truth Behind The Merger With India</td>\n",
       "      <td>GBS Sidhu</td>\n",
       "      <td>Hardcover,– 29 Oct 2018</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>6 customer reviews</td>\n",
       "      <td>It was in 1973 that G.B.S. Sidhu, a young official with the newly set-up Research and Analysis Wing (R&amp;AW), took charge of the field office in Gangtok in 1973. With an insider's view of the events that led to the Chogyal's ouster, he presents a first-hand account of the fledgling democracy movement and the struggle for reforms led by Kazi Lhendup Dorji in a society that was struggling to come to terms with the modern world.\\nIn his fast-paced, clear-sighted narrative, Sidhu tracks the reasons behind New Delhi's shift from a long-standing pro-Chogyal stand to a pro-democracy position and ma...</td>\n",
       "      <td>Government (Books)</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2449</td>\n",
       "      <td>Footprints on Zero Line: Writings on the Partition</td>\n",
       "      <td>Gulzar</td>\n",
       "      <td>Hardcover,– 20 Aug 2017</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>10 customer reviews</td>\n",
       "      <td>The Partition of 1947 has influenced the works of an entire generation of writers, and continues to do so. Gulzar witnessed the horrors of Partition first-hand and it is a theme that he has gone back to again and again in his writings. Footprints on Zero Line brings together a collection of his finest writings - fiction, non-fiction and poems - on the subject. What sets this collection apart from other writings on Partition is that Gulzar's unerring eye does not stop at the events of 1947 but looks at how it continues to affect our lives to this day. Wonderfully rendered in English by well...</td>\n",
       "      <td>Anthologies (Books)</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                                               Title  \\\n",
       "0  1589                                          R in Action, 2ed (MANNING)   \n",
       "1  2125                                   The Duchess Deal: Girl Meets Duke   \n",
       "2  5516     Learning React: Functional Web Development with React and Redux   \n",
       "3  1307  Sikkim - Dawn of Democracy: The Truth Behind The Merger With India   \n",
       "4  2449                  Footprints on Zero Line: Writings on the Partition   \n",
       "\n",
       "               Author                              Edition  \\\n",
       "0  Robert L. Kabacoff                     Paperback,– 2015   \n",
       "1          Tessa Dare  Mass Market Paperback,– 22 Aug 2017   \n",
       "2          Alex Banks                     Paperback,– 2017   \n",
       "3           GBS Sidhu              Hardcover,– 29 Oct 2018   \n",
       "4              Gulzar              Hardcover,– 20 Aug 2017   \n",
       "\n",
       "              Reviews              Ratings  \\\n",
       "0  4.0 out of 5 stars   7 customer reviews   \n",
       "1  4.8 out of 5 stars   7 customer reviews   \n",
       "2  4.8 out of 5 stars   6 customer reviews   \n",
       "3  4.2 out of 5 stars   6 customer reviews   \n",
       "4  4.5 out of 5 stars  10 customer reviews   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Synopsis  \\\n",
       "0                                                                                              R in Action, Second Edition teaches you how to use the R language by presenting examples relevant to scientific, technical and business developers. Focusing on practical solutions, the book offers a crash course in statistics, including elegant methods for dealing with messy and incomplete data. You'll also master R's extensive graphical capabilities for exploring and presenting data visually. And this expanded second edition includes new chapters on forecasting, data mining and dynamic report writing.   \n",
       "1  An iBooks Best Romance of August Pick!\\nOne of Publishers Weekly's Buzz Books of Romance 2017!\\nAn Amazon Best Romance of August Pick!\\n2017 RT Reviewer's Choice Book of the Year Nominee and 2017 RT Reviewer's Choice Nominee for Best Historical Love & Laughter!\\n When girl meets Duke, their marriage breaks all the rules…\\nSince his return from war, the Duke of Ashbury’s to-do list has been short and anything but sweet: brooding, glowering, menacing London ne’er-do-wells by night. Now there’s a new item on the list. He needs an heir—which means he needs a wife. When Emma Gladstone, a vicar’...   \n",
       "2  \"If you want to learn how to build efficient user interfaces with React, this is your book. Authors Alex Banks and Eve Porcello show you how to create UIs with this small JavaScript library that can deftly display data changes on large-scale, data-driven websites without page reloads. Along the way, youíll learn how to work with functional programming and the latest ECMAScript features.\\nDeveloped by Facebook and used by companies including Netflix, Walmart and The New York Times for large parts of their web interfaces, React is quickly growing in use. By learning how to build React compon...   \n",
       "3  It was in 1973 that G.B.S. Sidhu, a young official with the newly set-up Research and Analysis Wing (R&AW), took charge of the field office in Gangtok in 1973. With an insider's view of the events that led to the Chogyal's ouster, he presents a first-hand account of the fledgling democracy movement and the struggle for reforms led by Kazi Lhendup Dorji in a society that was struggling to come to terms with the modern world.\\nIn his fast-paced, clear-sighted narrative, Sidhu tracks the reasons behind New Delhi's shift from a long-standing pro-Chogyal stand to a pro-democracy position and ma...   \n",
       "4  The Partition of 1947 has influenced the works of an entire generation of writers, and continues to do so. Gulzar witnessed the horrors of Partition first-hand and it is a theme that he has gone back to again and again in his writings. Footprints on Zero Line brings together a collection of his finest writings - fiction, non-fiction and poems - on the subject. What sets this collection apart from other writings on Partition is that Gulzar's unerring eye does not stop at the events of 1947 but looks at how it continues to affect our lives to this day. Wonderfully rendered in English by well...   \n",
       "\n",
       "                    Genre                         BookCategory  \n",
       "0  Computer Science Books  Computing, Internet & Digital Media  \n",
       "1         Romance (Books)                              Romance  \n",
       "2  Internet & Web (Books)  Computing, Internet & Digital Media  \n",
       "3      Government (Books)                             Politics  \n",
       "4     Anthologies (Books)                             Politics  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/> \n",
    "Use this new dataset as input to the model you have just trained to predict Book Prices on it <br/>\n",
    "__TIP:__ look at the AutoGluon Tasks documentation and look for function __predict__ to see how to implement it [here](https://auto.gluon.ai/stable/api/autogluon.task.html#autogluon.tabular.TabularPredictor.predict).\n",
    "\n",
    "__Please, try hard to identify all information above before uncomment the answer below. You know, it is about Learn and Be Curious, right?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted prices for the first 10 books are : \n",
      " 0    2.631371\n",
      "1    2.491900\n",
      "2    2.814504\n",
      "3    2.809279\n",
      "4    2.633283\n",
      "5    2.693715\n",
      "6    2.697066\n",
      "7    2.728527\n",
      "8    2.424073\n",
      "9    2.436965\n",
      "Name: Price, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "############## CODE HERE ####################\n",
    "price_prediction = smaller_predictor.predict(df_test)\n",
    "print(\"predicted prices for the first 10 books are : \\n\", price_prediction[0:10])\n",
    "############## END OF CODE ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## CHALLENGE ANSWER\n",
    "# dayone_utils.answer_html(\"CH_PRED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"p1-6\">Part I - 6. First MLU Leaderboard Submission (with small train data)</a>\n",
    "#### Now you are ready for your first submission to our MLU Leaderboard!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/> \n",
    "> Run the cell below to save your prediction file in the format expected by the MLU Leaderboard.\n",
    "\n",
    "\n",
    "__NOTE__: If you have __not used the trained model to make predictions on the test dataset__ in the previous section/cell, you will not have the `price_predictions` needed for the prediction submission file, and running the cell below __will raise an error__. Go back and use the __.predict()__ function on the test dataset to create the `price_prediction` - as suggested by the answer provided in the *dayone_utils* file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "\n",
    "# Define empty dataset with column headers ID & Price\n",
    "df_submission = pd.DataFrame(columns=[\"ID\", \"Price\"])\n",
    "# Creating ID column from ID list\n",
    "df_submission[\"ID\"] = df_test[\"ID\"].tolist()\n",
    "# Creating label column from price prediction list\n",
    "df_submission[\"Price\"] = price_prediction\n",
    "# saving your csv file for Leaderboard submission\n",
    "df_submission.to_csv(\n",
    "    \"./datasets/predictions/Prediction_to_Leaderboard.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do a quick check to see if the file is ok!\n",
    "> <img style=\"float: left; padding-right: 30px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/> \n",
    "> 1. Run the cell below to check if your submission file has the right IDs for the MLU Leaderboard.\n",
    "> 2. If the difference is zero you are good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double-check submission file against the original test file\n",
      "Differences between project result IDs and sample submission IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Run the code below\n",
    "print(\"Double-check submission file against the original test file\")\n",
    "sample_submission_df = pd.read_csv(\"./datasets/mlu-leaderboard-test.csv\", sep=\",\")\n",
    "print(\n",
    "    \"Differences between project result IDs and sample submission IDs:\",\n",
    "    (sample_submission_df[\"ID\"] != df_submission[\"ID\"]).sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the Prediction File and Submitting\n",
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/> \n",
    "> 1. Download the file you just saved to your local machine. <br/>\n",
    "> 2. Follow the instructions on the Leaderboard submission page: https://mlu.corp.amazon.com/contests/redirect/7 to submit your file.\n",
    "\n",
    "<br>\n",
    "You can find your submission file in the folder <code>datasets > predictions</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"p1-7\">Part I - 7. Second MLU Leaderboard Submission (with full train data)</a>\n",
    "\n",
    "> <img style=\"float: left;\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\" /> \n",
    "> Now that you made your first submission using the small sample from your dataset, repeat the process using the full dataset and submit again to see if your score gets better.<br>\n",
    "If you don't know how to write the code for this, uncomment the challenge answer; copy and paste it in the section below.\n",
    "\n",
    "__NOTE__: It should take around 12-15 minutes to run this training with our CPU. Just in case, use the `time_limit` parameter (in seconds) to limit the run time to 20 minutes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220209_235036\\\"\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220209_235036\\\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    5051\n",
      "Train Data Columns: 9\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (4.149249912590282, 1.414973347970818, 2.60147, 0.33003)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1656.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.52 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Title', 'Edition', 'Ratings', 'Synopsis']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 4920\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 4920 to 2229 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['ID']\n",
      "\t\t('object', [])       : 4 | ['Author', 'Reviews', 'Genre', 'BookCategory']\n",
      "\t\t('object', ['text']) : 4 | ['Title', 'Edition', 'Ratings', 'Synopsis']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    4 | ['Author', 'Reviews', 'Genre', 'BookCategory']\n",
      "\t\t('category', ['text_as_category'])  :    4 | ['Title', 'Edition', 'Ratings', 'Synopsis']\n",
      "\t\t('int', [])                         :    1 | ['ID']\n",
      "\t\t('int', ['binned', 'text_special']) :   56 | ['Title.char_count', 'Title.word_count', 'Title.capital_ratio', 'Title.lower_ratio', 'Title.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 2230 | ['__nlp__.000', '__nlp__.10', '__nlp__.10 customer', '__nlp__.10 customer reviews', '__nlp__.100', ...]\n",
      "\t17.5s = Fit runtime\n",
      "\t9 features in original data used to generate 2295 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 22.93 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 17.85s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 4545, Val Rows: 506\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 882.15s of the 882.1s of remaining time.\n",
      "\t-0.1341\t = Validation score   (mean_squared_error)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 881.89s of the 881.84s of remaining time.\n",
      "\t-0.1422\t = Validation score   (mean_squared_error)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 881.61s of the 881.56s of remaining time.\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-0.0457\t = Validation score   (mean_squared_error)\n",
      "\t6.58s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 874.68s of the 874.61s of remaining time.\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-0.0472\t = Validation score   (mean_squared_error)\n",
      "\t6.15s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 868.27s of the 868.18s of remaining time.\n",
      "\t-0.0549\t = Validation score   (mean_squared_error)\n",
      "\t201.03s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 666.86s of the 666.81s of remaining time.\n",
      "\t-0.0429\t = Validation score   (mean_squared_error)\n",
      "\t153.97s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 512.67s of the 512.61s of remaining time.\n",
      "\t-0.055\t = Validation score   (mean_squared_error)\n",
      "\t248.95s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 263.36s of the 263.31s of remaining time.\n",
      "\t-0.0425\t = Validation score   (mean_squared_error)\n",
      "\t55.96s\t = Training   runtime\n",
      "\t2.94s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 204.03s of the 203.98s of remaining time.\n",
      "\t-0.0452\t = Validation score   (mean_squared_error)\n",
      "\t18.66s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ... Training model for up to 185.02s of the 184.97s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ... Training model for up to 184.72s of the 184.67s of remaining time.\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-0.0458\t = Validation score   (mean_squared_error)\n",
      "\t28.31s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 151.35s of remaining time.\n",
      "\t-0.0389\t = Validation score   (mean_squared_error)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 749.14s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220209_235036\\\")\n"
     ]
    }
   ],
   "source": [
    "############## CODE HERE ####################\n",
    "predictor = TabularPredictor(label=\"Price\", eval_metric=\"mean_squared_error\").fit(train_data=df_train, time_limit=15*60)\n",
    "\n",
    "############## END OF CODE ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### CHALLENGE ANSWER\n",
    "#dayone_utils.answer_html(\"CH_FULL_PRED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second MLU Leaderboard Submission with the Full Train Dataset\n",
    "\n",
    "><img style=\"float: left; padding-right: 20px\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/> \n",
    "1. Run the AutoGluon leaderboard function for the smaller dataset in the first cell below.\n",
    "2. Run the AutoGluon leaderboard function for the full dataset in the second cell below.\n",
    "3. Compare the performances.\n",
    "\n",
    "__How can you explain the differences in `score_val` and `fit_time` columns?__\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.060205</td>\n",
       "      <td>0.423705</td>\n",
       "      <td>27.805055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269403</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.061911</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>15.360326</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>15.360326</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.064838</td>\n",
       "      <td>0.036998</td>\n",
       "      <td>1.181352</td>\n",
       "      <td>0.036998</td>\n",
       "      <td>1.181352</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.064974</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.676940</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.676940</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-0.066901</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>3.798078</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>3.798078</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.067591</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>1.935345</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>1.935345</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-0.069272</td>\n",
       "      <td>0.071544</td>\n",
       "      <td>3.943585</td>\n",
       "      <td>0.071544</td>\n",
       "      <td>3.943585</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-0.070022</td>\n",
       "      <td>0.056001</td>\n",
       "      <td>8.418169</td>\n",
       "      <td>0.056001</td>\n",
       "      <td>8.418169</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-0.072054</td>\n",
       "      <td>0.284660</td>\n",
       "      <td>7.381691</td>\n",
       "      <td>0.284660</td>\n",
       "      <td>7.381691</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-0.138151</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.146264</td>\n",
       "      <td>0.016815</td>\n",
       "      <td>0.022997</td>\n",
       "      <td>0.016815</td>\n",
       "      <td>0.022997</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val   fit_time  \\\n",
       "0   WeightedEnsemble_L2  -0.060205       0.423705  27.805055   \n",
       "1              CatBoost  -0.061911       0.042046  15.360326   \n",
       "2              LightGBM  -0.064838       0.036998   1.181352   \n",
       "3            LightGBMXT  -0.064974       0.040000   1.676940   \n",
       "4       RandomForestMSE  -0.066901       0.053004   3.798078   \n",
       "5               XGBoost  -0.067591       0.020001   1.935345   \n",
       "6         ExtraTreesMSE  -0.069272       0.071544   3.943585   \n",
       "7         LightGBMLarge  -0.070022       0.056001   8.418169   \n",
       "8       NeuralNetFastAI  -0.072054       0.284660   7.381691   \n",
       "9        KNeighborsUnif  -0.138151       0.021029   0.035250   \n",
       "10       KNeighborsDist  -0.146264       0.016815   0.022997   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000000           0.269403            2       True   \n",
       "1                 0.042046          15.360326            1       True   \n",
       "2                 0.036998           1.181352            1       True   \n",
       "3                 0.040000           1.676940            1       True   \n",
       "4                 0.053004           3.798078            1       True   \n",
       "5                 0.020001           1.935345            1       True   \n",
       "6                 0.071544           3.943585            1       True   \n",
       "7                 0.056001           8.418169            1       True   \n",
       "8                 0.284660           7.381691            1       True   \n",
       "9                 0.021029           0.035250            1       True   \n",
       "10                0.016815           0.022997            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          11  \n",
       "1           6  \n",
       "2           4  \n",
       "3           3  \n",
       "4           5  \n",
       "5           9  \n",
       "6           7  \n",
       "7          10  \n",
       "8           8  \n",
       "9           1  \n",
       "10          2  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## FIRST CODE HERE ####################\n",
    "smaller_predictor.leaderboard(silent=True)\n",
    "\n",
    "############## END OF CODE ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.038863</td>\n",
       "      <td>3.411076</td>\n",
       "      <td>263.730227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256883</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-0.042488</td>\n",
       "      <td>2.938345</td>\n",
       "      <td>55.956851</td>\n",
       "      <td>2.938345</td>\n",
       "      <td>55.956851</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0.130956</td>\n",
       "      <td>153.974200</td>\n",
       "      <td>0.130956</td>\n",
       "      <td>153.974200</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.045198</td>\n",
       "      <td>0.058603</td>\n",
       "      <td>18.657167</td>\n",
       "      <td>0.058603</td>\n",
       "      <td>18.657167</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.045700</td>\n",
       "      <td>0.140093</td>\n",
       "      <td>6.578702</td>\n",
       "      <td>0.140093</td>\n",
       "      <td>6.578702</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-0.045802</td>\n",
       "      <td>0.143079</td>\n",
       "      <td>28.306423</td>\n",
       "      <td>0.143079</td>\n",
       "      <td>28.306423</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.047194</td>\n",
       "      <td>0.113003</td>\n",
       "      <td>6.145207</td>\n",
       "      <td>0.113003</td>\n",
       "      <td>6.145207</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-0.054881</td>\n",
       "      <td>0.097542</td>\n",
       "      <td>201.027086</td>\n",
       "      <td>0.097542</td>\n",
       "      <td>201.027086</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-0.055049</td>\n",
       "      <td>0.085004</td>\n",
       "      <td>248.952299</td>\n",
       "      <td>0.085004</td>\n",
       "      <td>248.952299</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-0.134102</td>\n",
       "      <td>0.012999</td>\n",
       "      <td>0.198595</td>\n",
       "      <td>0.012999</td>\n",
       "      <td>0.198595</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.142179</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val    fit_time  \\\n",
       "0   WeightedEnsemble_L2  -0.038863       3.411076  263.730227   \n",
       "1       NeuralNetFastAI  -0.042488       2.938345   55.956851   \n",
       "2              CatBoost  -0.042937       0.130956  153.974200   \n",
       "3               XGBoost  -0.045198       0.058603   18.657167   \n",
       "4            LightGBMXT  -0.045700       0.140093    6.578702   \n",
       "5         LightGBMLarge  -0.045802       0.143079   28.306423   \n",
       "6              LightGBM  -0.047194       0.113003    6.145207   \n",
       "7       RandomForestMSE  -0.054881       0.097542  201.027086   \n",
       "8         ExtraTreesMSE  -0.055049       0.085004  248.952299   \n",
       "9        KNeighborsUnif  -0.134102       0.012999    0.198595   \n",
       "10       KNeighborsDist  -0.142179       0.013015    0.200400   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000000           0.256883            2       True   \n",
       "1                 2.938345          55.956851            1       True   \n",
       "2                 0.130956         153.974200            1       True   \n",
       "3                 0.058603          18.657167            1       True   \n",
       "4                 0.140093           6.578702            1       True   \n",
       "5                 0.143079          28.306423            1       True   \n",
       "6                 0.113003           6.145207            1       True   \n",
       "7                 0.097542         201.027086            1       True   \n",
       "8                 0.085004         248.952299            1       True   \n",
       "9                 0.012999           0.198595            1       True   \n",
       "10                0.013015           0.200400            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          11  \n",
       "1           8  \n",
       "2           6  \n",
       "3           9  \n",
       "4           3  \n",
       "5          10  \n",
       "6           4  \n",
       "7           5  \n",
       "8           7  \n",
       "9           1  \n",
       "10          2  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## SECOND CODE HERE ###############\n",
    "predictor.leaderboard(silent=True)\n",
    "\n",
    "############## END OF CODE ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CHALLENGE ANSWER\n",
    "#dayone_utils.answer_html(\"CH_FULL_LEAD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the second submission for MLU Leaderboard ready</a>\n",
    "\n",
    "><img style=\"float: left; padding-right: 20px\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/> \n",
    "> Write the code that creates the output file using the predictions from your second model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted prices for the first 10 books are : \n",
      " 0    2.788654\n",
      "1    2.599526\n",
      "2    2.864072\n",
      "3    2.611377\n",
      "4    2.725514\n",
      "5    2.976959\n",
      "6    2.584566\n",
      "7    2.837416\n",
      "8    2.485230\n",
      "9    2.322487\n",
      "Name: Price, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "############## CODE HERE ####################\n",
    "price_prediction_2 = predictor.predict(df_test)\n",
    "print(\"predicted prices for the first 10 books are : \\n\", price_prediction_2[0:10])\n",
    "\n",
    "# Define empty dataset with column headers ID & Price\n",
    "df_full_submission = pd.DataFrame(columns=[\"ID\", \"Price\"])\n",
    "# Creating ID column from ID list\n",
    "df_full_submission[\"ID\"] = df_test[\"ID\"].tolist()\n",
    "# Creating label column from price prediction list\n",
    "df_full_submission[\"Price\"] = price_prediction_2\n",
    "# saving your csv file for Leaderboard submission\n",
    "df_full_submission.to_csv(\n",
    "    \"./datasets/predictions/Prediction_to_Leaderboard_2.csv\", index=False\n",
    ")\n",
    "############## END OF CODE ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CHALLENGE ANSWER\n",
    "# dayone_utils.answer_html(\"CH_FULL_SUBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do a quick check to see if the file is ok related to the IDs expected\n",
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/> \n",
    "1. Run the cell below to check if your submission file has the right IDs for the MLU Leaderboard.\n",
    "2. If the difference is zero you are good to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double-check submission file against the original test file\n",
      "Differences between project result IDs and sample submission IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Run the code below\n",
    "print(\"Double-check submission file against the original test file\")\n",
    "sample_submission_df = pd.read_csv(\"./datasets/mlu-leaderboard-test.csv\", sep=\",\")\n",
    "print(\n",
    "    \"Differences between project result IDs and sample submission IDs:\",\n",
    "    (sample_submission_df[\"ID\"] != df_full_submission[\"ID\"]).sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/> \n",
    "> Submit again to MLU leaderboard to improve your score. For the submission use the link as before: https://mlu.corp.amazon.com/contests/redirect/7 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#  <a name=\"2\"> Part II - Advanced AutoGluon (OPTIONAL)</a>\n",
    "\n",
    "Now that you have made your first Leaderboard submission, let's practice using some advanced features of AutoGluon. <br/>\n",
    "- Part II - 1. <a href=\"#p2-1\">Explainability: Feature Importance</a>\n",
    "- Part II - 2. <a href=\"#p2-2\">Data Preprocessing: Cleaning & Missing Values</a>\n",
    "- Part II - 3. <a href=\"#p2-3\">Final (optional) MLU Leaderboard Submission (with full engineered data)</a>\n",
    "- Part II - 4. <a href=\"#p2-4\">Before You Go (clean up model artifacts)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"p2-1\">Part II - 1. Explainability</a>\n",
    "\n",
    "There are growing business needs and legislative regulations that require explanations of why a model made a certain decision.<br/>\n",
    "To better understand our trained predictor, we can estimate the overall importance of each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "A feature’s importance score represents the performance drop that results when the model makes predictions on a perturbed copy of the dataset where this feature’s values have been randomly shuffled across rows. A feature score of 0.01 would indicate that the predictive performance dropped by 0.01 when the feature was randomly shuffled. The higher the score a feature has, the more important it is to the model’s performance. If a feature has a negative score, this means that the feature is likely harmful to the final model, and a model trained without that feature  would be expected to achieve a better predictive performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img style=\"float: left;padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\" align=\"left\"/> \n",
    "> Run the code below to see the output of the AutoGluon feature importance function for the first model we have run, with only 1000 samples. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 9 features using 1000 rows with 3 shuffle sets...\n",
      "\t41.3s\t= Expected runtime (13.77s per shuffle set)\n",
      "\t34.2s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synopsis</th>\n",
       "      <td>0.056896</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3</td>\n",
       "      <td>0.072304</td>\n",
       "      <td>0.041488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edition</th>\n",
       "      <td>0.014196</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>3</td>\n",
       "      <td>0.016242</td>\n",
       "      <td>0.012149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <td>0.010605</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>3</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BookCategory</th>\n",
       "      <td>0.008616</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>0.006882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ratings</th>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>3</td>\n",
       "      <td>0.011259</td>\n",
       "      <td>0.005108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>0.007887</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>0.006449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reviews</th>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.001150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Author</th>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              importance    stddev   p_value  n  p99_high   p99_low\n",
       "Synopsis        0.056896  0.002689  0.000372  3  0.072304  0.041488\n",
       "Edition         0.014196  0.000357  0.000105  3  0.016242  0.012149\n",
       "Genre           0.010605  0.000629  0.000585  3  0.014209  0.007000\n",
       "BookCategory    0.008616  0.000303  0.000206  3  0.010351  0.006882\n",
       "Ratings         0.008183  0.000537  0.000715  3  0.011259  0.005108\n",
       "Title           0.007887  0.000251  0.000168  3  0.009324  0.006449\n",
       "Reviews         0.002575  0.000249  0.001547  3  0.004000  0.001150\n",
       "Author          0.000811  0.000078  0.001537  3  0.001258  0.000364\n",
       "ID              0.000573  0.000033  0.000557  3  0.000763  0.000383"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the code below\n",
    "smaller_predictor.feature_importance(df_train_smaller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"p2-2\">Part II - 2. Data Preprocessing</a>\n",
    "\n",
    "With AutoGluon you don't have to worry about which model to chose; indeed you can focus on the data itself. \n",
    "In the book price case, there are a few columns which are clearly very poorly encoded, most importantly the ```Edition``` column. <br/>\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "For this experiment, let's use our small dataset __df_train_smaller__ to make everything run a bit faster.\n",
    "\n",
    "> <img style=\"float: left;padding-right: 20px\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/> \n",
    "> Use the functions below to clean things up a bit and expand that data out.<br/>\n",
    "For this experiment, our feature engineering taks will be:<br/><br/>\n",
    ">1. Splitting the Column ```Edition``` into three new ones: ```hard_paper```, ```year``` and ```month```\n",
    ">2. Creating two numerical features based on the features ```Reviews``` and ```Ratings```, named ```Reviews-n``` and ```Ratings-n``` respectively.\n",
    ">3. Drop the old columns from the dataset: ```Edition```,  ```Reviews``` and ```Ratings```. \n",
    "\n",
    "__Please, try hard to solve the challenge before uncommenting for the answer below.__ <br/>\n",
    "\n",
    "\n",
    "__Day One is about Learn and Be Curious, right?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def first_num(in_val):\n",
    "    num_string = in_val.split(\" \")[0]\n",
    "    digits = re.sub(r\"[^0-9\\.]\", \"\", num_string)\n",
    "    return float(digits)\n",
    "\n",
    "\n",
    "def year_get(in_val):\n",
    "    m = re.compile(r\"\\d{4}\").findall(in_val)\n",
    "    # print(in_val, m)\n",
    "    if len(m) > 0:\n",
    "        return int(m[0])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def month_get(in_val):\n",
    "    m = re.compile(r\"Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec\").findall(in_val)\n",
    "    # print(in_val, m)\n",
    "    if len(m) > 0:\n",
    "        return m[0]\n",
    "    else:\n",
    "        return \"None\"\n",
    "\n",
    "\n",
    "def drop_features(in_feat):\n",
    "    train_data_feateng.drop(in_feat, axis=1, inplace=True)\n",
    "    val_data_feateng.drop(in_feat, axis=1, inplace=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CODE HERE ####################\n",
    "train_data_feateng = df_train_smaller.copy()\n",
    "val_data_feateng = df_test.copy()\n",
    "\n",
    "train_data_feateng[\"hard_paper\"] = [i.split(',')[0] for i in train_data_feateng[\"Edition\"]]\n",
    "\n",
    "train_data_feateng[\"year\"] = train_data_feateng[\"Edition\"].apply(year_get)\n",
    "train_data_feateng[\"month\"] = train_data_feateng[\"Edition\"].apply(month_get)\n",
    "\n",
    "train_data_feateng[\"Reviews-n\"] = train_data_feateng[\"Reviews\"].apply(first_num)\n",
    "train_data_feateng[\"Ratings-n\"] = train_data_feateng[\"Ratings\"].apply(first_num)\n",
    "\n",
    "val_data_feateng[\"hard_paper\"] = [i.split(',')[0] for i in val_data_feateng[\"Edition\"]]\n",
    "\n",
    "val_data_feateng[\"year\"] = val_data_feateng[\"Edition\"].apply(year_get)\n",
    "val_data_feateng[\"month\"] = val_data_feateng[\"Edition\"].apply(month_get)\n",
    "\n",
    "val_data_feateng[\"Reviews-n\"] = val_data_feateng[\"Reviews\"].apply(first_num)\n",
    "val_data_feateng[\"Ratings-n\"] = val_data_feateng[\"Ratings\"].apply(first_num)\n",
    "\n",
    "\n",
    "drop_features([\"Edition\", \"Reviews\",\"Ratings\"] )\n",
    "\n",
    "############## END OF CODE ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CHALLENGE ANSWER\n",
    "#dayone_utils.answer_html(\"CH_FEAT_ENG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><img style=\"float: left;padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/> \n",
    ">Now print the dataset with the new features to see how they look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell\n",
    "\n",
    "#train_data_feateng.head(2)\n",
    "(train_data_feateng[\"month\"]==\"None\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Missing values\n",
    "By doing the feature engineering above we introduced a new challenge. \n",
    "We might now have some missing data.\n",
    "\n",
    "> <img style=\"float: left;padding-right: 20px\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/> \n",
    "> Try to identify the features that may have missing values and how many are missing. <br/>\n",
    "__Are there any missing values?__\n",
    "\n",
    "__Please, try hard to solve the challenge before uncommenting for the answer below.__ <br/>\n",
    "\n",
    "\n",
    "__Day One is about Learn and Be Curious, right?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null values: \n",
      " ID              0\n",
      "Title           0\n",
      "Author          0\n",
      "Synopsis        0\n",
      "Genre           0\n",
      "BookCategory    0\n",
      "Price           0\n",
      "hard_paper      0\n",
      "year            3\n",
      "month           0\n",
      "Reviews-n       0\n",
      "Ratings-n       0\n",
      "dtype: int64\n",
      "\n",
      "month = None:  60\n",
      "year = None:  0\n",
      "hard_paper = None:  0\n"
     ]
    }
   ],
   "source": [
    "############## CODE HERE ####################\n",
    "import numpy as np\n",
    "#train_data_feateng.isna().any()\n",
    "\n",
    "print(\"null values: \\n\",pd.isna(train_data_feateng).sum())\n",
    "print(\"\\nmonth = None: \",(train_data_feateng[\"month\"]==\"None\").sum())\n",
    "print(\"year = None: \",(train_data_feateng[\"year\"]==\"None\").sum())\n",
    "print(\"hard_paper = None: \",(train_data_feateng[\"hard_paper\"]==\"None\").sum())\n",
    "############## END OF CODE ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## CHALLENGE ANSWER\n",
    "#dayone_utils.answer_html(\"CH_MISSING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/> \n",
    "> Let's train the model again with these new manually created features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220210_011831\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220210_011831\\\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 11\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (3.9542425094393248, 1.414973347970818, 2.60143, 0.33874)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1527.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.92 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Title', 'Synopsis', 'Genre']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 784\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 784 to 590 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 3 | ['year', 'Reviews-n', 'Ratings-n']\n",
      "\t\t('int', [])          : 1 | ['ID']\n",
      "\t\t('object', [])       : 4 | ['Author', 'BookCategory', 'hard_paper', 'month']\n",
      "\t\t('object', ['text']) : 3 | ['Title', 'Synopsis', 'Genre']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   4 | ['Author', 'BookCategory', 'hard_paper', 'month']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Title', 'Synopsis', 'Genre']\n",
      "\t\t('float', [])                       :   3 | ['year', 'Reviews-n', 'Ratings-n']\n",
      "\t\t('int', [])                         :   1 | ['ID']\n",
      "\t\t('int', ['binned', 'text_special']) :  51 | ['Title.char_count', 'Title.word_count', 'Title.capital_ratio', 'Title.lower_ratio', 'Title.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 591 | ['__nlp__.000', '__nlp__.about', '__nlp__.about the', '__nlp__.account', '__nlp__.across', ...]\n",
      "\t5.5s = Fit runtime\n",
      "\t11 features in original data used to generate 653 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.28 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.58s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.1342\t = Validation score   (mean_squared_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.1367\t = Validation score   (mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-0.0657\t = Validation score   (mean_squared_error)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-0.0693\t = Validation score   (mean_squared_error)\n",
      "\t2.34s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.0691\t = Validation score   (mean_squared_error)\n",
      "\t3.88s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.0645\t = Validation score   (mean_squared_error)\n",
      "\t18.93s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.0679\t = Validation score   (mean_squared_error)\n",
      "\t4.88s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 4: early stopping\n",
      "\t-0.08\t = Validation score   (mean_squared_error)\n",
      "\t4.93s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.0687\t = Validation score   (mean_squared_error)\n",
      "\t1.75s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-0.0755\t = Validation score   (mean_squared_error)\n",
      "\t4.72s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.0624\t = Validation score   (mean_squared_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 50.83s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220210_011831\\\")\n"
     ]
    }
   ],
   "source": [
    "############## CODE HERE ####################\n",
    "smaller_feateng_predictor = TabularPredictor(label=\"Price\", eval_metric=\"mean_squared_error\").fit(train_data=train_data_feateng)\n",
    "\n",
    "############## END OF CODE ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## CHALLENGE ANSWER\n",
    "# dayone_utils.answer_html(\"CH_PRED_FEAT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/> \n",
    "> Compare the AutoGluon leaderboard for the new pfeateng_redictor to smaller_predictor in the cells below. <br/>\n",
    "__Are there any significant differences?__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.060205</td>\n",
       "      <td>0.423705</td>\n",
       "      <td>27.805055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269403</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.061911</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>15.360326</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>15.360326</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.064838</td>\n",
       "      <td>0.036998</td>\n",
       "      <td>1.181352</td>\n",
       "      <td>0.036998</td>\n",
       "      <td>1.181352</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.064974</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.676940</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.676940</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-0.066901</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>3.798078</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>3.798078</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.067591</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>1.935345</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>1.935345</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-0.069272</td>\n",
       "      <td>0.071544</td>\n",
       "      <td>3.943585</td>\n",
       "      <td>0.071544</td>\n",
       "      <td>3.943585</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-0.070022</td>\n",
       "      <td>0.056001</td>\n",
       "      <td>8.418169</td>\n",
       "      <td>0.056001</td>\n",
       "      <td>8.418169</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-0.072054</td>\n",
       "      <td>0.284660</td>\n",
       "      <td>7.381691</td>\n",
       "      <td>0.284660</td>\n",
       "      <td>7.381691</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-0.138151</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.146264</td>\n",
       "      <td>0.016815</td>\n",
       "      <td>0.022997</td>\n",
       "      <td>0.016815</td>\n",
       "      <td>0.022997</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val   fit_time  \\\n",
       "0   WeightedEnsemble_L2  -0.060205       0.423705  27.805055   \n",
       "1              CatBoost  -0.061911       0.042046  15.360326   \n",
       "2              LightGBM  -0.064838       0.036998   1.181352   \n",
       "3            LightGBMXT  -0.064974       0.040000   1.676940   \n",
       "4       RandomForestMSE  -0.066901       0.053004   3.798078   \n",
       "5               XGBoost  -0.067591       0.020001   1.935345   \n",
       "6         ExtraTreesMSE  -0.069272       0.071544   3.943585   \n",
       "7         LightGBMLarge  -0.070022       0.056001   8.418169   \n",
       "8       NeuralNetFastAI  -0.072054       0.284660   7.381691   \n",
       "9        KNeighborsUnif  -0.138151       0.021029   0.035250   \n",
       "10       KNeighborsDist  -0.146264       0.016815   0.022997   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000000           0.269403            2       True   \n",
       "1                 0.042046          15.360326            1       True   \n",
       "2                 0.036998           1.181352            1       True   \n",
       "3                 0.040000           1.676940            1       True   \n",
       "4                 0.053004           3.798078            1       True   \n",
       "5                 0.020001           1.935345            1       True   \n",
       "6                 0.071544           3.943585            1       True   \n",
       "7                 0.056001           8.418169            1       True   \n",
       "8                 0.284660           7.381691            1       True   \n",
       "9                 0.021029           0.035250            1       True   \n",
       "10                0.016815           0.022997            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          11  \n",
       "1           6  \n",
       "2           4  \n",
       "3           3  \n",
       "4           5  \n",
       "5           9  \n",
       "6           7  \n",
       "7          10  \n",
       "8           8  \n",
       "9           1  \n",
       "10          2  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## FIRST CODE FROM THE ANSWER HERE ####################\n",
    "smaller_predictor.leaderboard(silent=True)\n",
    "\n",
    "############## END OF CODE ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.062411</td>\n",
       "      <td>0.231073</td>\n",
       "      <td>29.202604</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.298880</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.064478</td>\n",
       "      <td>0.050565</td>\n",
       "      <td>18.926666</td>\n",
       "      <td>0.050565</td>\n",
       "      <td>18.926666</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.065743</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>1.011851</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>1.011851</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-0.067900</td>\n",
       "      <td>0.090509</td>\n",
       "      <td>4.879728</td>\n",
       "      <td>0.090509</td>\n",
       "      <td>4.879728</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.068657</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>1.748636</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>1.748636</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-0.069099</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>3.877837</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>3.877837</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.069263</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>2.336842</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>2.336842</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-0.075532</td>\n",
       "      <td>0.050999</td>\n",
       "      <td>4.723439</td>\n",
       "      <td>0.050999</td>\n",
       "      <td>4.723439</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-0.079989</td>\n",
       "      <td>0.252549</td>\n",
       "      <td>4.932153</td>\n",
       "      <td>0.252549</td>\n",
       "      <td>4.932153</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-0.134233</td>\n",
       "      <td>0.061999</td>\n",
       "      <td>0.051003</td>\n",
       "      <td>0.061999</td>\n",
       "      <td>0.051003</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.136711</td>\n",
       "      <td>0.025564</td>\n",
       "      <td>0.028004</td>\n",
       "      <td>0.025564</td>\n",
       "      <td>0.028004</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val   fit_time  \\\n",
       "0   WeightedEnsemble_L2  -0.062411       0.231073  29.202604   \n",
       "1              CatBoost  -0.064478       0.050565  18.926666   \n",
       "2            LightGBMXT  -0.065743       0.034000   1.011851   \n",
       "3         ExtraTreesMSE  -0.067900       0.090509   4.879728   \n",
       "4               XGBoost  -0.068657       0.017000   1.748636   \n",
       "5       RandomForestMSE  -0.069099       0.053004   3.877837   \n",
       "6              LightGBM  -0.069263       0.038000   2.336842   \n",
       "7         LightGBMLarge  -0.075532       0.050999   4.723439   \n",
       "8       NeuralNetFastAI  -0.079989       0.252549   4.932153   \n",
       "9        KNeighborsUnif  -0.134233       0.061999   0.051003   \n",
       "10       KNeighborsDist  -0.136711       0.025564   0.028004   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000999           0.298880            2       True   \n",
       "1                 0.050565          18.926666            1       True   \n",
       "2                 0.034000           1.011851            1       True   \n",
       "3                 0.090509           4.879728            1       True   \n",
       "4                 0.017000           1.748636            1       True   \n",
       "5                 0.053004           3.877837            1       True   \n",
       "6                 0.038000           2.336842            1       True   \n",
       "7                 0.050999           4.723439            1       True   \n",
       "8                 0.252549           4.932153            1       True   \n",
       "9                 0.061999           0.051003            1       True   \n",
       "10                0.025564           0.028004            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          11  \n",
       "1           6  \n",
       "2           3  \n",
       "3           7  \n",
       "4           9  \n",
       "5           5  \n",
       "6           4  \n",
       "7          10  \n",
       "8           8  \n",
       "9           1  \n",
       "10          2  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## SECOND CODE FROM THE ANSWER HERE ####################\n",
    "smaller_feateng_predictor.leaderboard(silent=True)\n",
    "\n",
    "############## END OF CODE #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CHALLENGE ANSWER\n",
    "# dayone_utils.answer_html(\"CH_LEAD_COMP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img style=\"float: left; padding-right: 30px\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/> \n",
    "1. Run the AutoGluon `feature_importance` function for original smaller dataset into the first cell below.\n",
    "2. Run the feature_importance function again for the feature engineered dataset into the second cell below.\n",
    "3. Compare the results.\n",
    "\n",
    "__Are there any significant differences?__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 9 features using 1000 rows with 3 shuffle sets...\n",
      "\t51.08s\t= Expected runtime (17.03s per shuffle set)\n",
      "\t37.07s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synopsis</th>\n",
       "      <td>0.056896</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3</td>\n",
       "      <td>0.072304</td>\n",
       "      <td>0.041488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edition</th>\n",
       "      <td>0.014196</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>3</td>\n",
       "      <td>0.016242</td>\n",
       "      <td>0.012149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <td>0.010605</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>3</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BookCategory</th>\n",
       "      <td>0.008616</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>0.006882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ratings</th>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>3</td>\n",
       "      <td>0.011259</td>\n",
       "      <td>0.005108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>0.007887</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>0.006449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reviews</th>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.001150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Author</th>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              importance    stddev   p_value  n  p99_high   p99_low\n",
       "Synopsis        0.056896  0.002689  0.000372  3  0.072304  0.041488\n",
       "Edition         0.014196  0.000357  0.000105  3  0.016242  0.012149\n",
       "Genre           0.010605  0.000629  0.000585  3  0.014209  0.007000\n",
       "BookCategory    0.008616  0.000303  0.000206  3  0.010351  0.006882\n",
       "Ratings         0.008183  0.000537  0.000715  3  0.011259  0.005108\n",
       "Title           0.007887  0.000251  0.000168  3  0.009324  0.006449\n",
       "Reviews         0.002575  0.000249  0.001547  3  0.004000  0.001150\n",
       "Author          0.000811  0.000078  0.001537  3  0.001258  0.000364\n",
       "ID              0.000573  0.000033  0.000557  3  0.000763  0.000383"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## CODE FOR THE ORIGINAL DATASET FEATURE IMPORTANCE HERE ####################\n",
    "smaller_predictor.feature_importance(df_train_smaller)\n",
    "\n",
    "############## END OF CODE ############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 11 features using 1000 rows with 3 shuffle sets...\n",
      "\t43.32s\t= Expected runtime (14.44s per shuffle set)\n",
      "\t30.45s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synopsis</th>\n",
       "      <td>0.057548</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>3</td>\n",
       "      <td>0.072062</td>\n",
       "      <td>0.043034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>3</td>\n",
       "      <td>0.016880</td>\n",
       "      <td>0.008804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_paper</th>\n",
       "      <td>0.010553</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>3</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>0.007562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>0.009263</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>0.007730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ratings-n</th>\n",
       "      <td>0.009136</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.008736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BookCategory</th>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>0.004518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.001645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reviews-n</th>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.000721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Author</th>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              importance    stddev   p_value  n  p99_high   p99_low\n",
       "Synopsis        0.057548  0.002533  0.000323  3  0.072062  0.043034\n",
       "Genre           0.012842  0.000705  0.000501  3  0.016880  0.008804\n",
       "hard_paper      0.010553  0.000522  0.000407  3  0.013544  0.007562\n",
       "Title           0.009263  0.000268  0.000139  3  0.010796  0.007730\n",
       "Ratings-n       0.009136  0.000070  0.000010  3  0.009535  0.008736\n",
       "BookCategory    0.005504  0.000172  0.000163  3  0.006490  0.004518\n",
       "month           0.002197  0.000096  0.000319  3  0.002748  0.001645\n",
       "Reviews-n       0.001502  0.000153  0.001719  3  0.002379  0.000626\n",
       "year            0.001099  0.000066  0.000599  3  0.001476  0.000721\n",
       "Author          0.000878  0.000054  0.000628  3  0.001186  0.000569\n",
       "ID              0.000505  0.000012  0.000098  3  0.000576  0.000435"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## CODE FOR THE FEATURE ENGINEERED DATASET FEATURE IMPORTANCE HERE  ####################\n",
    "smaller_feateng_predictor.feature_importance(train_data_feateng)\n",
    "\n",
    "############## END OF CODE #########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CHALLENGE ANSWER\n",
    "# dayone_utils.answer_html(\"CH_FEAT_COMP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"p2-3\">Part II - 3. Final (optional) MLU Leaderboard Submission (with full engineered data)</a>\n",
    "Let's create the full engineered dataset to train a final AutoGluon model & let's also allocate more time to really get the best results.\n",
    "\n",
    "__NOTE__: As there are few columns in this dataset, we don't necessarily expect additional performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/> \n",
    "> Now it is time to train your model using using AutoGluon __enhanced version__.\n",
    "\n",
    "For this experiment we will use a time limit of 30 min (`time_limit` in seconds below).\n",
    "\n",
    "__NOTE__: 20 minutes may not be enough to have a better score than your previous submission. If you have time, try running for more than 20 minutes to improve your performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feateng = df_train.copy()\n",
    "\n",
    "# CLEAN FEATURES\n",
    "full_feateng['Reviews-n'] = full_feateng['Reviews'].apply(first_num)\n",
    "full_feateng['Ratings-n'] = full_feateng['Ratings'].apply(first_num)\n",
    "full_feateng['hard-paper'] = full_feateng['Edition'].apply(lambda x : x.split(\",\")[0])\n",
    "full_feateng['year'] = full_feateng['Edition'].apply(year_get)\n",
    "full_feateng['month'] = full_feateng['Edition'].apply(month_get)\n",
    "\n",
    "# DROPING ORIGINAL FEATURES\n",
    "full_feateng.drop(['Edition', 'Ratings', 'Reviews'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220210_012701\\\"\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220210_012701\\\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    5051\n",
      "Train Data Columns: 11\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (4.149249912590282, 1.414973347970818, 2.60147, 0.33003)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1216.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.81 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Title', 'Synopsis']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 4595\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 4595 to 1483 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 3 | ['Reviews-n', 'Ratings-n', 'year']\n",
      "\t\t('int', [])          : 1 | ['ID']\n",
      "\t\t('object', [])       : 5 | ['Author', 'Genre', 'BookCategory', 'hard-paper', 'month']\n",
      "\t\t('object', ['text']) : 2 | ['Title', 'Synopsis']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    5 | ['Author', 'Genre', 'BookCategory', 'hard-paper', 'month']\n",
      "\t\t('category', ['text_as_category'])  :    2 | ['Title', 'Synopsis']\n",
      "\t\t('float', [])                       :    3 | ['Reviews-n', 'Ratings-n', 'year']\n",
      "\t\t('int', [])                         :    1 | ['ID']\n",
      "\t\t('int', ['binned', 'text_special']) :   44 | ['Title.char_count', 'Title.word_count', 'Title.capital_ratio', 'Title.lower_ratio', 'Title.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 1484 | ['__nlp__.000', '__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.20', ...]\n",
      "\t16.5s = Fit runtime\n",
      "\t11 features in original data used to generate 1539 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.44 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 16.77s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 4545, Val Rows: 506\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 1783.23s of the 1783.21s of remaining time.\n",
      "\t-0.1217\t = Validation score   (mean_squared_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 1783.09s of the 1783.07s of remaining time.\n",
      "\t-0.1248\t = Validation score   (mean_squared_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 1782.95s of the 1782.93s of remaining time.\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's l2: 0.00300236\tvalid_set's l2: 0.0457485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0456\t = Validation score   (mean_squared_error)\n",
      "\t14.34s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 1768.23s of the 1768.19s of remaining time.\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-0.0463\t = Validation score   (mean_squared_error)\n",
      "\t5.66s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 1762.35s of the 1762.29s of remaining time.\n",
      "\t-0.0549\t = Validation score   (mean_squared_error)\n",
      "\t137.27s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 1624.66s of the 1624.62s of remaining time.\n",
      "\t-0.0417\t = Validation score   (mean_squared_error)\n",
      "\t137.71s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 1486.8s of the 1486.78s of remaining time.\n",
      "\t-0.0549\t = Validation score   (mean_squared_error)\n",
      "\t167.13s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 1319.37s of the 1319.33s of remaining time.\n",
      "\t-0.0461\t = Validation score   (mean_squared_error)\n",
      "\t40.96s\t = Training   runtime\n",
      "\t1.08s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 1277.1s of the 1277.07s of remaining time.\n",
      "\t-0.0445\t = Validation score   (mean_squared_error)\n",
      "\t9.47s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ... Training model for up to 1267.39s of the 1267.36s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ... Training model for up to 1267.21s of the 1267.19s of remaining time.\n",
      "C:\\Users\\byunfei\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-0.0436\t = Validation score   (mean_squared_error)\n",
      "\t25.14s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1238.76s of remaining time.\n",
      "\t-0.0393\t = Validation score   (mean_squared_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 561.66s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220210_012701\\\")\n"
     ]
    }
   ],
   "source": [
    "enhanced_predictor = TabularPredictor(label=\"Price\", eval_metric=\"mean_squared_error\").fit(\n",
    "    train_data=full_feateng, time_limit= 30 * 60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to make Your Final Submission to the MLU Leaderboard</a>\n",
    "\n",
    "> <img style=\"float: left;padding-right: 20px\" src=\"./images/challenge_robot.png\" alt=\"drawing\" width=\"130\"/> \n",
    "> Now make a final prediction and submit this to MLU leaderboard.<br> Keep in mind that we used an engineered version of the dataset for training. We need to apply the same transformation to the test data before we can call `.predict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_feateng = df_test.copy()\n",
    "\n",
    "# FOR TEST DATA \n",
    "test_data_feateng['Reviews-n'] = test_data_feateng['Reviews'].apply(first_num)\n",
    "test_data_feateng['Ratings-n'] = test_data_feateng['Ratings'].apply(first_num)\n",
    "test_data_feateng['hard-paper'] = test_data_feateng['Edition'].apply(lambda x : x.split(\",\")[0])\n",
    "test_data_feateng['year'] = test_data_feateng['Edition'].apply(year_get)\n",
    "test_data_feateng['month'] = test_data_feateng['Edition'].apply(month_get)\n",
    "\n",
    "# DROPING ORIGINAL FEATURES\n",
    "test_data_feateng.drop(['Edition', 'Ratings', 'Reviews'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the code below to create predictions and the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted prices for the first 10 books are : \n",
      " 0    2.764384\n",
      "1    2.564892\n",
      "2    2.948368\n",
      "3    2.648545\n",
      "4    2.776495\n",
      "5    2.977696\n",
      "6    2.612196\n",
      "7    2.883893\n",
      "8    2.389546\n",
      "9    2.293916\n",
      "Name: Price, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "############## CODE HERE ####################\n",
    "price_prediction_3 = enhanced_predictor.predict(test_data_feateng)\n",
    "print(\"predicted prices for the first 10 books are : \\n\", price_prediction_3[0:10])\n",
    "\n",
    "# Define empty dataset with column headers ID & Price\n",
    "df_enhanced_submission = pd.DataFrame(columns=[\"ID\", \"Price\"])\n",
    "# Creating ID column from ID list\n",
    "df_enhanced_submission[\"ID\"] = test_data_feateng[\"ID\"].tolist()\n",
    "# Creating label column from price prediction list\n",
    "df_enhanced_submission[\"Price\"] = price_prediction_3\n",
    "# saving your csv file for Leaderboard submission\n",
    "df_enhanced_submission.to_csv(\n",
    "    \"./datasets/predictions/Prediction_to_Leaderboard_3.csv\", index=False\n",
    ")\n",
    "\n",
    "############## END OF CODE ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CHALLENGE ANSWER\n",
    "# dayone_utils.answer_html(\"CH_FINAL_SUBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do a quick check to see if the file is ok related to the IDs expected\n",
    "><img style=\"float: left; padding-right: 30px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/> \n",
    "> 1. Run the cell below to check if your submission file has the right IDs for the MLU Leaderboard.\n",
    "2. If the difference is zero you are good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double-check submission file against the original test file\n",
      "Differences between project result IDs and sample submission IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Run the code below\n",
    "print(\"Double-check submission file against the original test file\")\n",
    "sample_submission_df = pd.read_csv(\"./datasets/mlu-leaderboard-test.csv\", sep=\",\")\n",
    "print(\n",
    "    \"Differences between project result IDs and sample submission IDs:\",\n",
    "    (sample_submission_df[\"ID\"] != df_enhanced_submission[\"ID\"]).sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"./images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n",
    "    \n",
    "## Congrats for Finishing this Hands On!!\n",
    "In the next module, __Code Walkthrough and Advanced AutoGluon__ we are going do a walkthrough over your solutions and also show a notebook that implements an __end-to-end__ solution, deploying your model for use in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"p2-4\">Part II - 4. Before You Go</a>\n",
    "> <img style=\"float: left; padding-right: 20px\" src=\"./images/task_robot.png\" alt=\"drawing\" width=\"100\"/> \n",
    ">After you are done with this Hands On, you can clean all model artifacts uncommenting and executing the cell below.<br/>\n",
    "\n",
    "__It's always a good practice to clean up everything when you are done.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r AutogluonModels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
